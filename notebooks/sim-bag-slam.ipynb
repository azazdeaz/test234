{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vscode won't find the correct cwd when the jupyter server runs remotely (in docker)\n",
    "import os\n",
    "try:\n",
    "    os.chdir('/catkin_ws/src/notebooks/') # notebook bath in docker\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from msg_to_se3 import msg_to_se3\n",
    "import tf\n",
    "import itertools\n",
    "from nav_msgs.msg import Path\n",
    "import struct\n",
    "from sensor_msgs import point_cloud2 as pc2\n",
    "from sensor_msgs.msg import PointCloud2, PointField, Image, Imu\n",
    "from geometry_msgs.msg import PoseStamped, Point, Pose, TransformStamped, Transform\n",
    "from std_msgs.msg import Header\n",
    "import cv2\n",
    "import gtsam\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import gtsam.utils.plot as gtsam_plot\n",
    "from warnings import warn\n",
    "import rospy\n",
    "import rosbag\n",
    "import tf2_ros\n",
    "from cv_bridge import CvBridge\n",
    "bridge = CvBridge()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('roscore &')\n",
    "os.system('rosrun rviz rviz -d ./rviz/gentest.rviz &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node('sim_bag_slam', anonymous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"rosrun tf2_ros static_transform_publisher 0 0 0  0.5, 0.5, 0.5, 0.5 map z_ahead &\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Viz():\n",
    "    frame_id = \"z_ahead\"\n",
    "    pub_image = rospy.Publisher('render', Image, queue_size=1)\n",
    "    pub_camera = rospy.Publisher('camera', PoseStamped, queue_size=1)\n",
    "    pub_path_initial_estimate = rospy.Publisher(\"initial_estimate\", Path, queue_size=1)\n",
    "    pub_path_ground_truth = rospy.Publisher(\"truth\", Path, queue_size=1)\n",
    "    pub_path_optimized = rospy.Publisher(\"optimized\", Path, queue_size=1)\n",
    "    pub_path_imu = rospy.Publisher(\"imu_path\", Path, queue_size=1)\n",
    "\n",
    "    @classmethod\n",
    "    def keypoints(cls, img, frame):\n",
    "        for x, y in [kp.pt for kp in frame.kps]:\n",
    "            # print(\"center\", center)\n",
    "            # print(img.shape)\n",
    "            cv2.circle(img, (int(x), int(y)), radius=1, color=(0,255,128), thickness=1)\n",
    "        cls.pub_image.publish(bridge.cv2_to_imgmsg(img, encoding=\"rgb8\"))\n",
    "\n",
    "    @classmethod\n",
    "    def camera_pose(cls, transform):\n",
    "        cls.pub_camera.publish(transform.to_ros_pose_stamped())\n",
    "\n",
    "    @staticmethod\n",
    "    def path(transforms):\n",
    "        path = Path()\n",
    "        path.poses = [t.to_ros_pose_stamped() for t in transforms]\n",
    "        path.header.frame_id = Viz.frame_id\n",
    "        return path\n",
    "    @classmethod\n",
    "    def path_raw(cls, transforms):\n",
    "        cls.pub_path_initial_estimate.publish(cls.path(transforms))\n",
    "    @classmethod\n",
    "    def path_truth(cls, ros_poses):\n",
    "        path = Path()\n",
    "        path.poses = ros_poses\n",
    "        path.header.frame_id = \"ground_truth_zero\"\n",
    "        cls.pub_path_ground_truth.publish(path)\n",
    "    @classmethod\n",
    "    def path_optimized(cls, ros_poses):\n",
    "        path = Path()\n",
    "        path.poses = ros_poses\n",
    "        path.header.frame_id = Viz.frame_id\n",
    "        cls.pub_path_optimized.publish(path)\n",
    "    \n",
    "    @classmethod\n",
    "    def path_imu(cls, ros_poses):\n",
    "        path = Path()\n",
    "        path.poses = ros_poses\n",
    "        path.header.frame_id = \"map\"\n",
    "        cls.pub_path_imu.publish(path)\n",
    "\n",
    "class Frame():\n",
    "    def __init__(self, id, kps, descs):\n",
    "        self.id = id\n",
    "        self.kps = kps\n",
    "        self.descs = descs\n",
    "    \n",
    "    def symbol(self):\n",
    "        return gtsam.symbol('X', self.id)\n",
    "\n",
    "class Landmark():\n",
    "    _id = itertools.count(0)\n",
    "\n",
    "    def __init__(self, frame1, kp_index1, frame2, kp_index2):\n",
    "        self.symbol = gtsam.symbol('S', next(self._id))\n",
    "        self.observations = { frame1: kp_index1, frame2: kp_index2 }\n",
    "    def add_observation(self,frame, kp_index):\n",
    "        if frame in self.observations:\n",
    "            if kp_index == self.observations[frame]:\n",
    "                return\n",
    "            # warn(\"Star: tried to add a Frame #{} observation twice with differect KP indices ({}, {})\".format(frame.id, self.observations[frame], kp_index))\n",
    "            del self.observations[frame]\n",
    "        else:\n",
    "            self.observations[frame] = kp_index\n",
    "    def has(self, frame, kp_index):\n",
    "        return frame in self.observations and self.observations[frame] == kp_index\n",
    "\n",
    "class Transform():\n",
    "    def __init__(self, frame1, frame2, R, t):\n",
    "        assert (frame1 is None and frame2 is None) or (frame1.id < frame2.id)\n",
    "\n",
    "        self.frame1 = frame1\n",
    "        self.frame2 = frame2\n",
    "        self.R = R\n",
    "        self.t = t\n",
    "\n",
    "    @staticmethod\n",
    "    def from_ros_msg(msg):\n",
    "        h = msg_to_se3(ts)\n",
    "        return Transform(None, None, h[:3,:3], h[:3,3:])\n",
    "    \n",
    "    def to_ros_pose_stamped(self):\n",
    "        pose = PoseStamped()\n",
    "        pose.header.frame_id = Viz.frame_id\n",
    "        pose.header.stamp = rospy.Time.now()\n",
    "        pose.pose.position.x = self.t[0][0]\n",
    "        pose.pose.position.y = self.t[1][0]\n",
    "        pose.pose.position.z = self.t[2][0]\n",
    "        quaternion = R.from_matrix(self.R).as_quat()\n",
    "        pose.pose.orientation.x = quaternion[0]\n",
    "        pose.pose.orientation.y = quaternion[1]\n",
    "        pose.pose.orientation.z = quaternion[2]\n",
    "        pose.pose.orientation.w = quaternion[3]\n",
    "        return pose\n",
    "        \n",
    "    def __add__(self, transform2):\n",
    "        assert isinstance(transform2, Transform)\n",
    "        t = self.t + (self.R @ transform2.t)\n",
    "        R = transform2.R @ self.R\n",
    "        return Transform(self.frame1, transform2.frame2, R, t)\n",
    "\n",
    "    def projection_matrix(self):\n",
    "        x,y,z = self.t.T[0]\n",
    "        rot = self.R\n",
    "        return np.hstack((rot, [[x],[y],[z]]))\n",
    "\n",
    "class DecodeImageMsg():\n",
    "    @classmethod\n",
    "    def push(cls, msg):\n",
    "        cv_image = bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')\n",
    "        id = int(msg.header.stamp.to_time() * 10**9)\n",
    "        DetectAndComputeFrame.push(id, cv_image)\n",
    "\n",
    "class DetectAndComputeFrame():\n",
    "    detector = cv2.AKAZE_create()\n",
    "\n",
    "    @classmethod\n",
    "    def push(cls, id, img):\n",
    "        (next_kps, next_descs) = cls.detector.detectAndCompute(img, None)\n",
    "        frame = Frame(id, next_kps, next_descs)\n",
    "        Viz.keypoints(img, frame)\n",
    "        FuseImu.push_new_frame(frame)\n",
    "        GroundTruth.push_new_frame(frame)\n",
    "        CollectFrames.push(frame)\n",
    "\n",
    "class CollectFrames():\n",
    "    frames = []\n",
    "\n",
    "    @classmethod\n",
    "    def push(cls, frame):\n",
    "        cls.frames.append(frame)\n",
    "        if len(cls.frames) > 1:\n",
    "            EstimateTransform.push(cls.frames[-2], cls.frames[-1], raise_on_match_fail=True, add_to_initial_estimate=True)\n",
    "\n",
    "            go_back = np.minimum(len(cls.frames)-2, 8)\n",
    "            extra_count = np.minimum(go_back, 6)\n",
    "            extras = -(np.random.choice(go_back, extra_count, replace=False) + 3)\n",
    "            for i in extras:\n",
    "                EstimateTransform.push(cls.frames[i], cls.frames[-1], raise_on_match_fail=False,add_to_initial_estimate=False)\n",
    "\n",
    "class EstimateTransform():\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING) # TODO replace?\n",
    "    focal = 277.1\n",
    "    pp = (160.5, 120.5)\n",
    "\n",
    "    @classmethod\n",
    "    def push(cls, frame1, frame2, raise_on_match_fail=False, add_to_initial_estimate=False):\n",
    "        matches = cls.bf.knnMatch(frame1.descs, frame2.descs, k=2)\n",
    "        \n",
    "        matches_prev = []\n",
    "        matches_next = []\n",
    "        idx_prev = []\n",
    "        idx_next = []\n",
    "\n",
    "        matches = list(filter(lambda m: m[0].distance < 0.8*m[1].distance, matches))\n",
    "        if len(matches) < 40:\n",
    "            if raise_on_match_fail:\n",
    "                raise Exception(\"Failed to match frames. Found {} matches\".format(len(matches)))\n",
    "            return None\n",
    "\n",
    "        for m,n in matches:\n",
    "            matches_prev.append(frame1.kps[m.queryIdx].pt)\n",
    "            matches_next.append(frame2.kps[m.trainIdx].pt)\n",
    "            idx_prev.append(m.queryIdx)\n",
    "            idx_next.append(m.trainIdx)\n",
    "\n",
    "        matches_prev = np.array(matches_prev)\n",
    "        matches_next = np.array(matches_next)\n",
    "\n",
    "        E, mask = cv2.findEssentialMat(matches_prev, matches_next, focal=cls.focal, pp=cls.pp, method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "        \n",
    "        # for i, is_good_kp_index in enumerate(mask):\n",
    "        #     if is_good_kp_index:\n",
    "        #         CollectLandmarks.push(frame1, idx_prev[i], frame2, idx_next[i])\n",
    "            \n",
    "        \n",
    "        points, R_est, t_est, mask_pose = cv2.recoverPose(E, matches_prev, matches_next, focal=cls.focal, pp=cls.pp)\n",
    "        \n",
    "        # x,y,z,scale = self.truth.getPoseAndAbsoluteScale(frame1.id, frame2.id)\n",
    "        # convert to Z-up\n",
    "        # z_up_rotation = R.from_rotvec(np.array([np.pi/2,np.pi/2,0])).as_matrix()\n",
    "        # t_est = z_up_rotation @ t_est\n",
    "        # R_est = R_est @ z_up_rotation\n",
    "        # t = self.t + (self.R @ transform2.t)\n",
    "        # R = transform2.R @ self.R\n",
    "        # t_est = np.array([t_est[0],t_est[2],t_est[1]])\n",
    "        # scale = 0.05 # TODO\n",
    "        # scale = FuseImu.pull_scale_btwn(frame1, frame2)\n",
    "        scale = GroundTruth.pull_scale_btwn(frame1, frame2)\n",
    "        t_est *= scale\n",
    "\n",
    "        transform = Transform(frame1, frame2, R_est, t_est)\n",
    "\n",
    "        CollectTransforms.push(transform)\n",
    "        Graph.push_transform(transform)\n",
    "        if add_to_initial_estimate:\n",
    "            InitialPathEstimate.push(transform)\n",
    "\n",
    "class CollectLandmarks():\n",
    "    landmarks = []\n",
    "\n",
    "    @classmethod\n",
    "    def push(cls, frame1, kp_index1, frame2, kp_index2):\n",
    "        landmark = next((s for s in cls.landmarks if s.has(frame1, kp_index1)), None)\n",
    "        \n",
    "        if landmark:\n",
    "            landmark.add_observation(frame2, kp_index2)\n",
    "        else:\n",
    "            landmark = next((s for s in cls.landmarks if s.has(frame2, kp_index2)), None)\n",
    "            if landmark:\n",
    "                landmark.add_observation(frame1, kp_index2)\n",
    "            else:\n",
    "                cls.landmarks.append(Landmark(frame1, kp_index1, frame2, kp_index2))\n",
    "        \n",
    "class CollectTransforms():\n",
    "    transforms = []\n",
    "\n",
    "    @classmethod\n",
    "    def push(cls, transform):\n",
    "        cls.transforms.append(transform)\n",
    "\n",
    "        \n",
    "class FuseImu():\n",
    "    pub_orientation = rospy.Publisher('orientation', PoseStamped, queue_size=1)\n",
    "    pub_imu = rospy.Publisher('imu', Imu, queue_size=1)\n",
    "    vel = np.zeros((3,1))\n",
    "    translation = np.zeros((3,1))\n",
    "    # gravity in gazebo\n",
    "    gravity = np.array([0.0, 0.0, -9.8]).reshape((3,1))\n",
    "    prev_time = None\n",
    "    path = []\n",
    "    frame_translations = {}\n",
    "\n",
    "    @classmethod\n",
    "    def push_new_frame(cls, frame):\n",
    "        cls.frame_translations[frame] = cls.translation.copy()\n",
    "\n",
    "    @classmethod\n",
    "    def pull_scale_btwn(cls, frame1, frame2):\n",
    "        t1 = cls.frame_translations[frame1]\n",
    "        t2 = cls.frame_translations[frame2]\n",
    "        return np.linalg.norm(t2-t1)\n",
    "\n",
    "    @classmethod\n",
    "    def push(cls, msg: Imu):\n",
    "        is_first_message = cls.prev_time is None\n",
    "\n",
    "        curr_time = msg.header.stamp.to_sec()\n",
    "        if not is_first_message:\n",
    "            delta = curr_time - cls.prev_time\n",
    "        cls.prev_time = curr_time\n",
    "\n",
    "        if is_first_message:\n",
    "            return\n",
    "        \n",
    "        acc = np.array([\n",
    "            [ msg.linear_acceleration.x ],\n",
    "            [ msg.linear_acceleration.y ],\n",
    "            [ msg.linear_acceleration.z ],\n",
    "        ]) + cls.gravity\n",
    "        cls.vel += acc * delta\n",
    "        quat = np.array([\n",
    "            msg.orientation.x,\n",
    "            msg.orientation.y,\n",
    "            msg.orientation.z,\n",
    "            msg.orientation.w,\n",
    "        ])\n",
    "        \n",
    "        nudge = R.from_quat(quat).as_matrix() @ (cls.vel*delta)\n",
    "        cls.translation += nudge\n",
    "        # print(\"delta\", delta)\n",
    "        # print(\"nudge\", nudge)\n",
    "        # print(\"acc\", acc)\n",
    "        # print(\"cls.vel\", cls.vel)\n",
    "        pose = PoseStamped()\n",
    "        pose.header.frame_id = \"map\"\n",
    "        pose.header.stamp = rospy.Time.now()\n",
    "        pose.pose.position.x = cls.translation[0][0]\n",
    "        pose.pose.position.y = cls.translation[1][0]\n",
    "        pose.pose.position.z = cls.translation[2][0]\n",
    "        pose.pose.orientation.x = quat[0]\n",
    "        pose.pose.orientation.y = quat[1]\n",
    "        pose.pose.orientation.z = quat[2]\n",
    "        pose.pose.orientation.w = quat[3]\n",
    "        cls.path.append(pose)\n",
    "        Viz.path_imu(cls.path)\n",
    "        cls.pub_orientation.publish(pose)\n",
    "        cls.pub_imu.publish(msg)\n",
    "\n",
    "\n",
    "class InitialPathEstimate():\n",
    "    path = []\n",
    "    global_transform = None\n",
    "\n",
    "    @classmethod\n",
    "    def push(cls, transform): \n",
    "        if cls.global_transform is None:\n",
    "            cls.global_transform = transform\n",
    "        else:\n",
    "            cls.global_transform = cls.global_transform + transform \n",
    "        cls.path.append(cls.global_transform)\n",
    "\n",
    "        rot = gtsam.Rot3(cls.global_transform.R)\n",
    "        point = gtsam.Point3(cls.global_transform.t.T[0])\n",
    "        key = cls.global_transform.frame2.symbol()\n",
    "        Graph.initial_estimate.insert(key, gtsam.Pose3(rot, point))\n",
    "\n",
    "        Viz.camera_pose(cls.global_transform)\n",
    "        Viz.path_raw(cls.path)\n",
    "\n",
    "class GroundTruth():\n",
    "    path = []\n",
    "    last_transform = None\n",
    "    broadcaster = tf2_ros.StaticTransformBroadcaster()\n",
    "    frame_translations = {}\n",
    "\n",
    "    @classmethod\n",
    "    def push_new_frame(cls, frame):\n",
    "        cls.frame_translations[frame] = np.array([\n",
    "            [ cls.last_transform.translation.x ],\n",
    "            [ cls.last_transform.translation.y ],\n",
    "            [ cls.last_transform.translation.z ],\n",
    "        ])\n",
    "\n",
    "    @classmethod\n",
    "    def pull_scale_btwn(cls, frame1, frame2):\n",
    "        t1 = cls.frame_translations[frame1]\n",
    "        t2 = cls.frame_translations[frame2]\n",
    "        return np.linalg.norm(t2-t1)\n",
    "\n",
    "    @classmethod\n",
    "    def push(cls, ros_transform):\n",
    "        cls.last_transform = ros_transform\n",
    "        pose = PoseStamped(pose=Pose(ros_transform.translation, ros_transform.rotation))\n",
    "        cls.path.append(pose)\n",
    "        Viz.path_truth(cls.path)\n",
    "    \n",
    "    @classmethod\n",
    "    def trigger_zero_pose(cls):\n",
    "        # TODO handle when last_transform = None\n",
    "        static_transformStamped = TransformStamped()\n",
    "        static_transformStamped.header.stamp = rospy.Time.now()\n",
    "        static_transformStamped.header.frame_id = \"ground_truth_zero\"\n",
    "        static_transformStamped.child_frame_id = \"map\"\n",
    "        static_transformStamped.transform.translation.x = cls.last_transform.translation.x\n",
    "        static_transformStamped.transform.translation.y = cls.last_transform.translation.y\n",
    "        static_transformStamped.transform.translation.z = cls.last_transform.translation.z\n",
    "        static_transformStamped.transform.rotation.x = 0\n",
    "        static_transformStamped.transform.rotation.y = 0\n",
    "        static_transformStamped.transform.rotation.z = 1\n",
    "        static_transformStamped.transform.rotation.w = 0\n",
    "        cls.broadcaster.sendTransform(static_transformStamped)\n",
    "\n",
    "class Graph():\n",
    "    PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.3]*6))\n",
    "    ODOMETRY_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.3]*3 + [1.2]*3))\n",
    "\n",
    "    graph = gtsam.NonlinearFactorGraph()\n",
    "    initial_estimate = gtsam.Values()\n",
    "\n",
    "    @classmethod\n",
    "    def push_transform(cls, transform):\n",
    "        rot = gtsam.Rot3(transform.R)\n",
    "        point = gtsam.Point3(transform.t.T[0])\n",
    "        key1 = transform.frame1.symbol()\n",
    "        key2 = transform.frame2.symbol()\n",
    "        cls.graph.add(gtsam.BetweenFactorPose3(key1, key2, gtsam.Pose3(rot, point), cls.ODOMETRY_NOISE))\n",
    "\n",
    "    @classmethod\n",
    "    def dogleg_optimizer(cls):\n",
    "        params = gtsam.DoglegParams()\n",
    "        params.setVerbosity('TERMINATION')\n",
    "        return gtsam.Cal3_S2(cls.graph, cls.initial_estimate, params)\n",
    "\n",
    "    @classmethod\n",
    "    def gauss_newton_optimizer(cls):\n",
    "        parameters = gtsam.GaussNewtonParams()\n",
    "        # Stop iterating once the change in error between steps is less than this value\n",
    "        parameters.setRelativeErrorTol(1e-5)\n",
    "        # Do not perform more than N iteration steps\n",
    "        parameters.setMaxIterations(1000)\n",
    "        # Create the optimizer ...\n",
    "        return gtsam.GaussNewtonOptimizer(cls.graph, cls.initial_estimate, parameters)\n",
    "\n",
    "    @classmethod\n",
    "    def lm_optimizer(cls):\n",
    "        params = gtsam.LevenbergMarquardtParams()\n",
    "        params.setVerbosityLM(\"ERROR\")\n",
    "        return gtsam.LevenbergMarquardtOptimizer(cls.graph, cls.initial_estimate, params)\n",
    "\n",
    "    @classmethod\n",
    "    def pull_result(cls):\n",
    "        optimizer = cls.lm_optimizer() \n",
    "        # ... and optimize\n",
    "        result = optimizer.optimize()\n",
    "\n",
    "        def to_ros_pose_stamped(pose3):\n",
    "            quaternion = pose3.rotation().quaternion()\n",
    "            pose = PoseStamped()\n",
    "            pose.header.frame_id = Viz.frame_id\n",
    "            pose.header.stamp = rospy.Time.now()\n",
    "            pose.pose.position.x = pose3.x()\n",
    "            pose.pose.position.y = pose3.y()\n",
    "            pose.pose.position.z = pose3.z()\n",
    "            pose.pose.orientation.x = quaternion[0]\n",
    "            pose.pose.orientation.y = quaternion[1]\n",
    "            pose.pose.orientation.z = quaternion[2]\n",
    "            pose.pose.orientation.w = quaternion[3]\n",
    "            return pose\n",
    "\n",
    "        optimized = np.array([to_ros_pose_stamped(result.atPose3(f.symbol())) for f in CollectFrames.frames])\n",
    "        Viz.path_optimized(optimized)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "bag = rosbag.Bag('/bags/02.bag')\n",
    "got_first_frame = False\n",
    "for m in list(bag.read_messages())[:3200]:\n",
    "    # help(m.timestamp)\n",
    "    # print(m.topic, m.timestamp)\n",
    "    if m.topic.endswith(\"/front/image_raw\"):\n",
    "        DecodeImageMsg.push(m.message)\n",
    "        if not got_first_frame:\n",
    "            got_first_frame = True\n",
    "            GroundTruth.trigger_zero_pose()\n",
    "        # rospy.sleep(1.)\n",
    "    elif m.topic.endswith(\"/pose_static\"):\n",
    "        t = next(t.transform for t in m.message.transforms if t.child_frame_id == \"costar_husky_sensor_config_1\")\n",
    "        GroundTruth.push(t)\n",
    "    elif m.topic.endswith(\"/imu/data\"):\n",
    "        FuseImu.push(m.message)\n",
    "\n",
    "Graph.graph.add(gtsam.PriorFactorPose3(CollectFrames.frames[0].symbol(), gtsam.Pose3(), Graph.PRIOR_NOISE))\n",
    "Graph.initial_estimate.insert(CollectFrames.frames[0].symbol(), gtsam.Pose3())\n",
    "result = Graph.pull_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"rqt &\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(rosbag.Bag('/bags/02.bag'))[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CollectLandmarks.landmarks[0].observations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = np.zeros((len(CollectFrames.frames), len(CollectFrames.frames)))\n",
    "\n",
    "for l in CollectLandmarks.landmarks:\n",
    "    for f1 in l.observations.keys():\n",
    "        for f2 in l.observations.keys():\n",
    "            if f1 != f2:\n",
    "                x = CollectFrames.frames.index(f1)\n",
    "                y = CollectFrames.frames.index(f2)\n",
    "                cmap[x, y] += 1\n",
    "\n",
    "plt.imshow(cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = np.zeros((240,320))\n",
    "\n",
    "l = CollectLandmarks.landmarks[5360]\n",
    "for frame, kp_idx in l.observations.items():\n",
    "    x, y = frame.kps[kp_idx].pt\n",
    "    cmap[int(y), int(x)] += 1\n",
    "    print(frame.id, kp_idx, frame.kps[kp_idx].pt)\n",
    "\n",
    "plt.imshow(cmap)\n",
    "print(len(CollectLandmarks.landmarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph.graph.clone()\n",
    "initial_estimate = gtsam.Values(Graph.initial_estimate)\n",
    "measurement_noise = gtsam.noiseModel.Isotropic.Sigma(\n",
    "        2, 1.0)  # one pixel in u and v\n",
    "focal = 277.1\n",
    "pp = (160.5, 120.5)\n",
    "K = gtsam.Cal3_S2(focal, focal, 0.0, pp[0], pp[1])\n",
    "\n",
    "# Simulated measurements from each camera pose, adding them to the factor graph\n",
    "for l in CollectLandmarks.landmarks:\n",
    "    if len(l.observations) < 10:\n",
    "        continue\n",
    "    # Every landmark represent a single landmark, we use shared pointer to init the factor, and then insert measurements\n",
    "    smart_factor = gtsam.SmartProjectionPose3Factor(measurement_noise, K)\n",
    "\n",
    "    for frame, kp_index in l.observations.items():\n",
    "\n",
    "        try:\n",
    "            xy = np.array(frame.kps[kp_index].pt, dtype=np.float64)\n",
    "        except Exception:\n",
    "            print(len(frame.kps), kp_index)\n",
    "\n",
    "        # Add measurement to smart factor\n",
    "        smart_factor.add(xy, frame.symbol())\n",
    "    \n",
    "    # Insert the smart factor in the graph\n",
    "    graph.push_back(smart_factor)\n",
    "\n",
    "# Add a prior on pose x0\n",
    "# 30cm std on x,y,z 0.1 rad on roll,pitch,yaw\n",
    "pose_noise = gtsam.noiseModel.Diagonal.Sigmas(np.array(\n",
    "    [0.1, 0.1, 0.1, 0.3, 0.3, 0.3]))  \n",
    "pose = gtsam.Pose3()\n",
    "graph.push_back(gtsam.PriorFactorPose3(CollectFrames.frames[0].symbol(), pose, pose_noise))\n",
    "\n",
    "# Because the structure-from-motion problem has a scale ambiguity, the problem is\n",
    "# still under-constrained. Here we add a prior on the second pose x1, so this will\n",
    "# fix the scale by indicating the distance between x0 and x1.\n",
    "# Because these two are fixed, the rest of the poses will be also be fixed.\n",
    "pose = initial_estimate.atPose3(CollectFrames.frames[1].symbol())\n",
    "graph.push_back(gtsam.PriorFactorPose3(CollectFrames.frames[1].symbol(), pose, pose_noise)) # Add directly to graph\n",
    "graph.print_(\"Factor Graph:\\n\")\n",
    "\n",
    "initial_estimate.insert(CollectFrames.frames[0].symbol(), gtsam.Pose3())\n",
    "\n",
    "\n",
    "\n",
    "# Create the initial estimate to the solution\n",
    "# Intentionally initialize the variables off from the ground truth\n",
    "# delta = gtsam.Pose3(gtsam.Rot3.Rodrigues(-0.1, 0.2, 0.25), gtsam.Point3(0.05, -0.10, 0.20))\n",
    "# for i, pose in enumerate(poses):\n",
    "#     initial_estimate.insert(X(i), pose.compose(delta))\n",
    "# Pose3 delta(Rot3::Rodrigues(-0.1, 0.2, 0.25), Point3(0.05, -0.10, 0.20));\n",
    "# for (size_t i = 0; i < poses.size(); ++i)\n",
    "# initialEstimate.insert(i, poses[i].compose(delta));\n",
    "initial_estimate.print_(\"Initial Estimates:\\n\");\n",
    "# print(initial_estimate)\n",
    "\n",
    "params = gtsam.LevenbergMarquardtParams()\n",
    "# params.setMaxIterations(1)\n",
    "optimizer = gtsam.LevenbergMarquardtOptimizer(graph, initial_estimate, params)\n",
    "result = optimizer.optimize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ros_pose_stamped(p3: gtsam.Pose3):\n",
    "    translation = p3.translation()\n",
    "    quaternion = p3.rotation().toQuaternion()\n",
    "    pose = PoseStamped()\n",
    "    pose.header.frame_id = Viz.frame_id\n",
    "    pose.header.stamp = rospy.Time.now()\n",
    "    pose.pose.position.x = translation[0]\n",
    "    pose.pose.position.y = translation[1]\n",
    "    pose.pose.position.z = translation[2]\n",
    "    pose.pose.orientation.x = quaternion.x()\n",
    "    pose.pose.orientation.y = quaternion.y()\n",
    "    pose.pose.orientation.z = quaternion.z()\n",
    "    pose.pose.orientation.w = quaternion.w()\n",
    "    return pose\n",
    "\n",
    "optimized = np.array([to_ros_pose_stamped(result.atPose3(f.symbol())) for f in CollectFrames.frames])\n",
    "Viz.path_optimized(optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(gtsam.LevenbergMarquardtParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_path(X, Y, Z, label):\n",
    "    path_publisher = rospy.Publisher(label, Path, queue_size=1)\n",
    "\n",
    "    path_msg = Path()\n",
    "    path_msg.header.frame_id = 'map'\n",
    "    for x, y, z in zip(X, Y, Z):\n",
    "        pose_msg = PoseStamped()\n",
    "\n",
    "        pose_msg.pose.position.x = x / 100\n",
    "        pose_msg.pose.position.y = y / 100\n",
    "        pose_msg.pose.position.z = z / 100\n",
    "        pose_msg.pose.orientation.x = 0\n",
    "        pose_msg.pose.orientation.y = 0\n",
    "        pose_msg.pose.orientation.z = 0\n",
    "        pose_msg.pose.orientation.w = 1\n",
    "        path_msg.poses.append(pose_msg)\n",
    "\n",
    "    path_publisher.publish(path_msg)\n",
    "    \n",
    "viz_path(track[:,0,2], track[:,0,0], track[:,0,1], label=\"raw_est\")\n",
    "viz_path(-track[:,1,2], track[:,1,0], track[:,1,1], label=\"truth\")\n",
    "viz_path(optimized[:,2], optimized[:,0], -optimized[:,1], label=\"optimized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImuNoiseAngular():\n",
    "    mean = 0\n",
    "    stddev = 0.009\n",
    "    bias_mean = 0.00075\n",
    "    bias_stddev = 0.005\n",
    "    dynamic_bias_stddev = 0.00002\n",
    "    dynamic_bias_correlation_time = 400.0\n",
    "    precision = 0.00025\n",
    "\n",
    "class ImuNoiseLinear():\n",
    "    mean = 0\n",
    "    stddev = 0.021\n",
    "    bias_mean = 0.05\n",
    "    bias_stddev = 0.0075\n",
    "    dynamic_bias_stddev = 0.000375\n",
    "    dynamic_bias_correlation_time = 175.0\n",
    "    precision = 0.005\n",
    "\n",
    "class IntegrateImu():\n",
    "    @staticmethod\n",
    "    def defaultParams():\n",
    "        \"\"\"Create default parameters with Z *up* and realistic noise parameters\"\"\"\n",
    "        gravity = 9.81\n",
    "        params = gtsam.PreintegrationParams.MakeSharedU(gravity)\n",
    "        kGyroSigma = ImuNoiseAngular.stddev # math.radians(0.5) / 60  # 0.5 degree ARW\n",
    "        kAccelSigma = ImuNoiseLinear.stddev #0.1 / 60  # 10 cm VRW\n",
    "        params.setGyroscopeCovariance(\n",
    "            kGyroSigma ** 2 * np.identity(3, np.float))\n",
    "        params.setAccelerometerCovariance(\n",
    "            kAccelSigma ** 2 * np.identity(3, np.float))\n",
    "        params.setIntegrationCovariance(\n",
    "            0.0000001 ** 2 * np.identity(3, np.float))\n",
    "        return params\n",
    "\n",
    "    @staticmethod\n",
    "    def default_bias():\n",
    "            accBias = np.array([ImuNoiseLinear.bias_mean] * 3)\n",
    "            gyroBias = np.array([ImuNoiseAngular.bias_mean] * 3)\n",
    "            return gtsam.imuBias.ConstantBias(accBias, gyroBias)\n",
    "\n",
    "    BIAS_KEY = gtsam.symbol('B', 0)\n",
    "    pim = gtsam.PreintegratedImuMeasurements(IntegrateImu.defaultParams(), IntegrateImu.default_bias())\n",
    "    prev_message = None\n",
    "\n",
    "    @classmethod\n",
    "    def push(cls, msg: sensor_msgs.msg.Imu):\n",
    "        if cls.prev_message is None:\n",
    "            initial.insert(BIAS_KEY, self.actualBias)\n",
    "        self.velNoise = gtsam.noiseModel.Isotropic.Sigma(3, 0.1)\n",
    "            graph.push_back(gtsam.PriorFactorVector(\n",
    "            V(i), state.velocity(), self.velNoise))\n",
    "            initial.insert(V(i), initial_state_i.velocity())\n",
    "        else:\n",
    "            dt = (msg.header.stamp - cls.prev_message.header.stamp).to_sec()\n",
    "            measuredAcc = np.array([msg.linear_acceleration.x, msg.linear_acceleration.y, msg.linear_acceleration.z])\n",
    "            measuredOmega = np.array([msg.angular_velocity.x, msg.angular_velocity.y, msg.angular_velocity.z])\n",
    "            cls.pim.integrateMeasurement(measuredAcc, measuredOmega, dt)\n",
    "\n",
    "        \n",
    "        cls.prev_message = msg\n",
    "\n",
    "    @classmethod\n",
    "    def push_frame(cls, id):\n",
    "        # create IMU factor every second\n",
    "        factor = gtsam.ImuFactor2(gtsam.symbol('X', i), gtsam.symbol('V', i),\n",
    "                                 gtsam.symbol('X', i + 1), gtsam.symbol('V', i + 1),\n",
    "                                 cls.BIAS_KEY, cls.pim)\n",
    "        graph.push_back(factor)\n",
    "        pim.resetIntegration()\n",
    "\n",
    "        rotationNoise = gtsam.Rot3.Expmap(np.random.randn(3)*0.1)\n",
    "        translationNoise = gtsam.Point3(*np.random.randn(3)*1)\n",
    "        poseNoise = gtsam.Pose3(rotationNoise, translationNoise)\n",
    "\n",
    "        actual_state_i = self.scenario.navState(t + self.dt)\n",
    "        print(\"Actual state at {0}:\\n{1}\".format(\n",
    "            t+self.dt, actual_state_i))\n",
    "\n",
    "        noisy_state_i = gtsam.NavState(\n",
    "            actual_state_i.pose().compose(poseNoise),\n",
    "            actual_state_i.velocity() + np.random.randn(3)*0.1)\n",
    "\n",
    "        # initial.insert(X(i+1), noisy_state_i.pose())\n",
    "        # initial.insert(V(i+1), noisy_state_i.velocity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GTSAM Copyright 2010-2019, Georgia Tech Research Corporation,\n",
    "Atlanta, Georgia 30332-0415\n",
    "All Rights Reserved\n",
    "See LICENSE for the license information\n",
    "A script validating the Preintegration of IMU measurements\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "\n",
    "import gtsam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gtsam.utils.plot import plot_pose3\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "IMU_FIG = 1\n",
    "POSES_FIG = 2\n",
    "\n",
    "\n",
    "class PreintegrationExample(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def defaultParams(g):\n",
    "        \"\"\"Create default parameters with Z *up* and realistic noise parameters\"\"\"\n",
    "        params = gtsam.PreintegrationParams.MakeSharedU(g)\n",
    "        kGyroSigma = math.radians(0.5) / 60  # 0.5 degree ARW\n",
    "        kAccelSigma = 0.1 / 60  # 10 cm VRW\n",
    "        params.setGyroscopeCovariance(\n",
    "            kGyroSigma ** 2 * np.identity(3, np.float))\n",
    "        params.setAccelerometerCovariance(\n",
    "            kAccelSigma ** 2 * np.identity(3, np.float))\n",
    "        params.setIntegrationCovariance(\n",
    "            0.0000001 ** 2 * np.identity(3, np.float))\n",
    "        return params\n",
    "\n",
    "    def __init__(self, twist=None, bias=None, dt=1e-2):\n",
    "        \"\"\"Initialize with given twist, a pair(angularVelocityVector, velocityVector).\"\"\"\n",
    "\n",
    "        # setup interactive plotting\n",
    "        plt.ion()\n",
    "\n",
    "        # Setup loop as default scenario\n",
    "        if twist is not None:\n",
    "            (W, V) = twist\n",
    "        else:\n",
    "            # default = loop with forward velocity 2m/s, while pitching up\n",
    "            # with angular velocity 30 degree/sec (negative in FLU)\n",
    "            W = np.array([0, -math.radians(30), 0])\n",
    "            V = np.array([2, 0, 0])\n",
    "\n",
    "        self.scenario = gtsam.ConstantTwistScenario(W, V)\n",
    "        self.dt = dt\n",
    "\n",
    "        self.maxDim = 5\n",
    "        self.labels = list('xyz')\n",
    "        self.colors = list('rgb')\n",
    "\n",
    "        # Create runner\n",
    "        self.g = 10  # simple gravity constant\n",
    "        self.params = self.defaultParams(self.g)\n",
    "\n",
    "        if bias is not None:\n",
    "            self.actualBias = bias\n",
    "        else:\n",
    "            accBias = np.array([0, 0.1, 0])\n",
    "            gyroBias = np.array([0, 0, 0])\n",
    "            self.actualBias = gtsam.imuBias.ConstantBias(accBias, gyroBias)\n",
    "\n",
    "        self.runner = gtsam.ScenarioRunner(\n",
    "            self.scenario, self.params, self.dt, self.actualBias)\n",
    "\n",
    "        fig, self.axes = plt.subplots(4, 3)\n",
    "        fig.set_tight_layout(True)\n",
    "\n",
    "    def plotImu(self, t, measuredOmega, measuredAcc):\n",
    "        plt.figure(IMU_FIG)\n",
    "\n",
    "        # plot angular velocity\n",
    "        omega_b = self.scenario.omega_b(t)\n",
    "        for i, (label, color) in enumerate(zip(self.labels, self.colors)):\n",
    "            ax = self.axes[0][i]\n",
    "            ax.scatter(t, omega_b[i], color='k', marker='.')\n",
    "            ax.scatter(t, measuredOmega[i], color=color, marker='.')\n",
    "            ax.set_xlabel('angular velocity ' + label)\n",
    "\n",
    "        # plot acceleration in nav\n",
    "        acceleration_n = self.scenario.acceleration_n(t)\n",
    "        for i, (label, color) in enumerate(zip(self.labels, self.colors)):\n",
    "            ax = self.axes[1][i]\n",
    "            ax.scatter(t, acceleration_n[i], color=color, marker='.')\n",
    "            ax.set_xlabel('acceleration in nav ' + label)\n",
    "\n",
    "        # plot acceleration in body\n",
    "        acceleration_b = self.scenario.acceleration_b(t)\n",
    "        for i, (label, color) in enumerate(zip(self.labels, self.colors)):\n",
    "            ax = self.axes[2][i]\n",
    "            ax.scatter(t, acceleration_b[i], color=color, marker='.')\n",
    "            ax.set_xlabel('acceleration in body ' + label)\n",
    "\n",
    "        # plot actual specific force, as well as corrupted\n",
    "        actual = self.runner.actualSpecificForce(t)\n",
    "        for i, (label, color) in enumerate(zip(self.labels, self.colors)):\n",
    "            ax = self.axes[3][i]\n",
    "            ax.scatter(t, actual[i], color='k', marker='.')\n",
    "            ax.scatter(t, measuredAcc[i], color=color, marker='.')\n",
    "            ax.set_xlabel('specific force ' + label)\n",
    "\n",
    "    def plotGroundTruthPose(self, t, scale=0.3, time_interval=0.01):\n",
    "        # plot ground truth pose, as well as prediction from integrated IMU measurements\n",
    "        actualPose = self.scenario.pose(t)\n",
    "        plot_pose3(POSES_FIG, actualPose, scale)\n",
    "        t = actualPose.translation()\n",
    "        self.maxDim = max([max(np.abs(t)), self.maxDim])\n",
    "        ax = plt.gca()\n",
    "        ax.set_xlim3d(-self.maxDim, self.maxDim)\n",
    "        ax.set_ylim3d(-self.maxDim, self.maxDim)\n",
    "        ax.set_zlim3d(-self.maxDim, self.maxDim)\n",
    "\n",
    "        plt.pause(time_interval)\n",
    "\n",
    "    def run(self, T=12):\n",
    "        # simulate the loop\n",
    "        for i, t in enumerate(np.arange(0, T, self.dt)):\n",
    "            measuredOmega = self.runner.measuredAngularVelocity(t)\n",
    "            measuredAcc = self.runner.measuredSpecificForce(t)\n",
    "            if i % 25 == 0:\n",
    "                self.plotImu(t, measuredOmega, measuredAcc)\n",
    "                self.plotGroundTruthPose(t)\n",
    "                pim = self.runner.integrate(t, self.actualBias, True)\n",
    "                predictedNavState = self.runner.predict(pim, self.actualBias)\n",
    "                plot_pose3(POSES_FIG, predictedNavState.pose(), 0.1)\n",
    "\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    PreintegrationExample().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cv2.findEssentialMat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}